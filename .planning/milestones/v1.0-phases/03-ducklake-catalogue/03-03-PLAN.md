---
phase: 03-ducklake-catalogue
plan: 03
type: execute
wave: 3
depends_on: ["03-01", "03-02"]
files_modified:
  - scripts/configure_retention.sql
  - scripts/validate_ducklake.R
autonomous: false

must_haves:
  truths:
    - "An analyst can query a table at a past snapshot using AT (VERSION => N)"
    - "Snapshot retention is configured to expire old snapshots automatically"
    - "An analyst can see what changed between data refreshes via table_changes()"
    - "End-to-end validation confirms all Phase 3 success criteria are met"
  artefacts:
    - path: "scripts/configure_retention.sql"
      provides: "SQL for snapshot retention policy"
      contains: "expire_older_than"
    - path: "scripts/validate_ducklake.R"
      provides: "Comprehensive validation script for all Phase 3 criteria"
      contains: "AT (VERSION"
  key_links:
    - from: "scripts/validate_ducklake.R"
      to: "s3://stevecrawshaw-bucket/ducklake/mca_env.ducklake"
      via: "ATTACH DuckLake catalogue and run validation queries"
      pattern: "mca_env.ducklake"
---

<objective>
Configure snapshot retention, validate time travel and data change feed, and run end-to-end validation of the complete DuckLake catalogue.

Purpose: Time travel and change feed are key DuckLake features that differentiate it from raw parquet on S3. The validation script confirms all Phase 3 success criteria are met before marking the phase complete.
Output: A validated DuckLake catalogue with retention policy and a reusable validation script.
</objective>

<execution_context>
@C:\Users\steve.crawshaw\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\steve.crawshaw\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/03-ducklake-catalogue/03-RESEARCH.md
@.planning/phases/03-ducklake-catalogue/03-CONTEXT.md
@.planning/phases/03-ducklake-catalogue/03-01-SUMMARY.md
@.planning/phases/03-ducklake-catalogue/03-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Configure retention, test time travel and change feed</name>
  <files>scripts/configure_retention.sql, scripts/validate_ducklake.R</files>
  <action>
Create two files:

**scripts/configure_retention.sql** -- SQL statements for snapshot retention:
```sql
-- Set retention policy: expire snapshots older than 90 days
-- Note: DuckLake retention is database-wide, not per-table.
-- The user requested "last 5 versions per table" but DuckLake snapshots are
-- database-level. Using time-based retention (90 days) as the closest equivalent.
CALL lake.set_option('expire_older_than', '90 days');
```

**scripts/validate_ducklake.R** -- Comprehensive validation script that:

1. Opens an in-memory DuckDB connection
2. Installs and loads `ducklake`, `httpfs`, `aws` extensions
3. Creates S3 secret with credential_chain
4. Attaches catalogue in READ_WRITE mode (needed for time travel test with data modification):
   `ATTACH 'ducklake:s3://stevecrawshaw-bucket/ducklake/mca_env.ducklake' AS lake (DATA_PATH 's3://stevecrawshaw-bucket/ducklake/data/')`

5. **Validation 1 -- Table count**: Query `SELECT COUNT(*) FROM information_schema.tables WHERE table_catalog = 'lake' AND table_type = 'BASE TABLE'` and assert result is 18.

6. **Validation 2 -- Table comments**: Query `SELECT COUNT(*) FROM duckdb_tables() WHERE database_name = 'lake' AND comment IS NOT NULL AND comment != ''` and assert >= 15 (some tables may have uninformative auto-generated comments that were still copied).

7. **Validation 3 -- Column comments**: Query `SELECT COUNT(*) FROM duckdb_columns() WHERE database_name = 'lake' AND comment IS NOT NULL AND comment != ''` and assert >= 600 (source has ~663).

8. **Validation 4 -- Views**: Query `SELECT COUNT(*) FROM information_schema.tables WHERE table_catalog = 'lake' AND table_type = 'VIEW'` and assert >= 12 (4 source views + 8 WECA views).

9. **Validation 5 -- Time travel**:
   a. Query current snapshot: `SELECT * FROM lake.snapshots() ORDER BY snapshot_id DESC LIMIT 1` -- record the version number
   b. Insert a test row into a small table: `INSERT INTO lake.ca_la_lookup_tbl VALUES ('TEST', 'Test Authority', 'TEST_CA', 'Test Combined')` (or similar, matching column structure)
   c. Query current version: `SELECT COUNT(*) FROM lake.ca_la_lookup_tbl` (should be original + 1)
   d. Query at previous version: `SELECT COUNT(*) FROM lake.ca_la_lookup_tbl AT (VERSION => {previous_version})` (should be original count)
   e. Assert the two counts differ by 1
   f. Delete the test row: `DELETE FROM lake.ca_la_lookup_tbl WHERE LAD25CD = 'TEST'`
   g. Print "Time travel: PASS"

10. **Validation 6 -- Data change feed**:
    a. Get snapshot IDs from step 9 (before and after insert)
    b. Query: `SELECT * FROM lake.table_changes('ca_la_lookup_tbl', {version_before}, {version_after})`
    c. Assert result contains at least 1 row showing the insert
    d. Print "Data change feed: PASS"

11. **Validation 7 -- Snapshot retention configuration**:
    a. Execute the retention SQL from configure_retention.sql
    b. Print "Retention configured: 90 days"

12. **Validation 8 -- Analyst read-only access simulation**:
    a. Detach the lake
    b. Re-attach as READ_ONLY: `ATTACH 'ducklake:s3://stevecrawshaw-bucket/ducklake/mca_env.ducklake' AS lake (READ_ONLY)`
    c. Query: `SELECT * FROM lake.la_ghg_emissions_weca_vw LIMIT 5`
    d. Query: `DESCRIBE lake.la_ghg_emissions_tbl` to confirm column info accessible
    e. Assert both queries succeed
    f. Print "Analyst access: PASS"

13. Print summary: X/8 validations passed

Use tryCatch around each validation so individual failures are logged but don't halt the script. Print PASS/FAIL for each validation.
  </action>
  <verify>
Run `scripts/validate_ducklake.R` from the project root. All 8 validations should pass:
1. Table count: 18
2. Table comments: >= 15
3. Column comments: >= 600
4. Views: >= 12
5. Time travel: PASS
6. Data change feed: PASS
7. Retention configured
8. Analyst access: PASS
  </verify>
  <done>
Time travel works (querying at previous version returns correct data). Data change feed shows insert/delete operations. Snapshot retention set to 90 days. All 8 validations pass.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <what-built>Complete DuckLake catalogue with 18 tables, comments, 12 views, time travel, and retention policy</what-built>
  <how-to-verify>
1. Open a DuckDB CLI session and run:
   ```sql
   INSTALL ducklake; LOAD ducklake;
   CREATE SECRET (TYPE s3, REGION 'eu-west-2', PROVIDER credential_chain);
   ATTACH 'ducklake:s3://stevecrawshaw-bucket/ducklake/mca_env.ducklake' AS lake (READ_ONLY);
   USE lake;
   ```

2. Check tables are visible:
   ```sql
   SHOW TABLES;
   ```
   Expected: 18 tables listed

3. Check a table comment:
   ```sql
   SELECT comment FROM duckdb_tables() WHERE database_name = 'lake' AND table_name = 'la_ghg_emissions_tbl';
   ```
   Expected: "Local authority greenhouse gas emissions (long format)"

4. Check column comments:
   ```sql
   SELECT column_name, comment FROM duckdb_columns()
   WHERE database_name = 'lake' AND table_name = 'boundary_lookup_tbl' AND comment IS NOT NULL
   LIMIT 5;
   ```

5. Query a WECA view:
   ```sql
   SELECT DISTINCT local_authority_code FROM la_ghg_emissions_weca_vw;
   ```
   Expected: E06000022, E06000023, E06000024, E06000025

6. Check time travel (if version > 1):
   ```sql
   SELECT * FROM lake.snapshots();
   SELECT COUNT(*) FROM la_ghg_emissions_tbl AT (VERSION => 1);
   ```
  </how-to-verify>
  <resume-signal>Type "approved" or describe issues</resume-signal>
</task>

</tasks>

<verification>
1. All 8 automated validations pass in validate_ducklake.R
2. User confirms catalogue is accessible from DuckDB CLI
3. Table and column comments visible
4. WECA views return correctly filtered data
5. Time travel query returns data from a previous version
</verification>

<success_criteria>
Time travel works. Data change feed works. Retention is configured. End-to-end validation passes 8/8. User confirms the catalogue is functional from DuckDB CLI.
</success_criteria>

<output>
After completion, create `.planning/phases/03-ducklake-catalogue/03-03-SUMMARY.md`
</output>
